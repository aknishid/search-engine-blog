{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CISIデータセットを使った検索精度検証\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの準備\n",
    "[CISI](https://www.kaggle.com/datasets/dmaso01dsta/cisi-a-dataset-for-information-retrieval)データセットを利用します。関連ドキュメントIDが提供されているため、検索精度を定量的に評価できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "def load_data(path):\n",
    "    \n",
    "    #_____________ Read data from CISI.ALL file and store in dictinary ________________\n",
    "    \n",
    "    with open(os.path.join(path, 'CISI.ALL')) as f:\n",
    "        lines = \"\"\n",
    "        for l in f.readlines():\n",
    "            lines += \"\\n\" + l.strip() if l.startswith(\".\") else \" \" + l.strip()\n",
    "        lines = lines.lstrip(\"\\n\").split(\"\\n\")\n",
    " \n",
    "    doc_set = {}\n",
    "    doc_id = 0\n",
    "    doc_text = \"\"\n",
    "\n",
    "    for l in lines:\n",
    "        if l.startswith(\".I\"):\n",
    "            doc_id = int(l.split(\" \")[1].strip())\n",
    "        elif l.startswith(\".X\"):\n",
    "            doc_set[doc_id] = doc_text.lstrip(\" \")\n",
    "            doc_id = \"\"\n",
    "            doc_text = \"\"\n",
    "        else:\n",
    "            doc_text += l.strip()[3:] + \" \" \n",
    "\n",
    "    print(f\"Number of documents = {len(doc_set)}\")\n",
    "    print(doc_set[1]) \n",
    "    \n",
    "    \n",
    "    #_____________ Read data from CISI.QRY file and store in dictinary ________________\n",
    "    \n",
    "    with open(os.path.join(path, 'CISI.QRY')) as f:\n",
    "        lines = \"\"\n",
    "        for l in f.readlines():\n",
    "            lines += \"\\n\" + l.strip() if l.startswith(\".\") else \" \" + l.strip()\n",
    "        lines = lines.lstrip(\"\\n\").split(\"\\n\")\n",
    "          \n",
    "    qry_set = {}\n",
    "    qry_id = 0\n",
    "    for l in lines:\n",
    "        if l.startswith(\".I\"):\n",
    "            qry_id = int(l.split(\" \")[1].strip())\n",
    "        elif l.startswith(\".W\"):\n",
    "            qry_set[qry_id] = l.strip()[3:]\n",
    "            qry_id = \"\"\n",
    "\n",
    "    print(f\"\\n\\nNumber of queries = {len(qry_set)}\")    \n",
    "    print(qry_set[1]) \n",
    "    \n",
    "    \n",
    "    #_____________ Read data from CISI.REL file and store in dictinary ________________\n",
    "    \n",
    "    rel_set = {}\n",
    "    with open(os.path.join(path, 'CISI.REL')) as f:\n",
    "        for l in f.readlines():\n",
    "            qry_id = int(l.lstrip(\" \").strip(\"\\n\").split(\"\\t\")[0].split(\" \")[0])\n",
    "            doc_id = int(l.lstrip(\" \").strip(\"\\n\").split(\"\\t\")[0].split(\" \")[-1])\n",
    "\n",
    "            if qry_id in rel_set:\n",
    "                rel_set[qry_id].append(doc_id)\n",
    "            else:\n",
    "                rel_set[qry_id] = []\n",
    "                rel_set[qry_id].append(doc_id)\n",
    "\n",
    "    print(f\"\\n\\nNumber of mappings = {len(rel_set)}\")\n",
    "    print(rel_set[1]) \n",
    "    \n",
    "    return doc_set, qry_set, rel_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents = 1460\n",
      "18 Editions of the Dewey Decimal Classifications Comaromi, J.P. The present study is a history of the DEWEY Decimal Classification.  The first edition of the DDC was published in 1876, the eighteenth edition in 1971, and future editions will continue to appear as needed.  In spite of the DDC's long and healthy life, however, its full story has never been told.  There have been biographies of Dewey that briefly describe his system, but this is the first attempt to provide a detailed history of the work that more than any other has spurred the growth of librarianship in this country and abroad. \n",
      "\n",
      "\n",
      "Number of queries = 112\n",
      "What problems and concerns are there in making up descriptive titles? What difficulties are involved in automatically retrieving articles from approximate titles? What is the usual relevance of the content of articles to their titles?\n",
      "\n",
      "\n",
      "Number of mappings = 76\n",
      "[28, 35, 38, 42, 43, 52, 65, 76, 86, 150, 189, 192, 193, 195, 215, 269, 291, 320, 429, 465, 466, 482, 483, 510, 524, 541, 576, 582, 589, 603, 650, 680, 711, 722, 726, 783, 813, 820, 868, 869, 894, 1162, 1164, 1195, 1196, 1281]\n"
     ]
    }
   ],
   "source": [
    "doc_set, qry_set, rel_set = load_data('./input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Query Set: 76\n"
     ]
    }
   ],
   "source": [
    "# rel_setは全ての関連するドキュメントのIDを持っているわけではないのでqry_setをフィルタリング\n",
    "related_ids = set(rel_set.keys())\n",
    "filtered_qry_set = {qid: qry_set[qid] for qid in related_ids if qid in qry_set}\n",
    "\n",
    "print(f\"Filtered Query Set: {len(filtered_qry_set.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# model = SentenceTransformer('msmarco-distilbert-base-tas-b')\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for doc_id, doc_text in tqdm(doc_set.items()):\n",
    "    embeddings = model.encode(doc_text, convert_to_tensor=True)\n",
    "    embeddings_list = embeddings.cpu().numpy().tolist()\n",
    "    data.append({'id': doc_id, 'vector': embeddings_list})\n",
    "\n",
    "# DataFrameに変換\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# CSVに保存\n",
    "df.to_csv('document_embeddings.csv', index=False)\n",
    "\n",
    "print(\"Embeddings have been saved to document_embeddings.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for qry_id, qry_text in tqdm(filtered_qry_set.items()):\n",
    "    embeddings = model.encode(qry_text, convert_to_tensor=True)\n",
    "    embeddings_list = embeddings.cpu().numpy().tolist()\n",
    "    data.append({'id': qry_id, 'vector': embeddings_list})\n",
    "\n",
    "# DataFrameに変換\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# CSVに保存\n",
    "df.to_csv('query_embeddings.csv', index=False)\n",
    "\n",
    "print(\"Embeddings have been saved to query_embeddings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "train_df = pd.read_csv('document_embeddings.csv')\n",
    "test_df = pd.read_csv('query_embeddings.csv')\n",
    "train_df['vector'] = train_df['vector'].apply(eval).apply(np.array)\n",
    "test_df['vector'] = test_df['vector'].apply(eval).apply(np.array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df['vector'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1460, 2), (76, 2))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 精度の計算\n",
    "精度の評価には、Mean Reciprocal Rank（MRR）を利用します。\n",
    "\n",
    "MRRとは、各クエリに対して、最初に出現する関連ドキュメントの順位の逆数を平均したものです。\n",
    "\n",
    "$$\n",
    "\\text{MRR} = \\frac{1}{N} \\sum_{i=1}^{N} \\frac{1}{\\text{rank}_i}\n",
    "$$\n",
    "\n",
    "ここで、$\\{Q_1, Q_2, \\ldots, Q_N\\}$ はクエリセットを表し、$\\text{rank}_i$ はクエリ $Q_i$ の検索結果に対して正しい答えが何番目に出てくるかを示しています。\n",
    "\n",
    "\n",
    "MRRが大きいと、関連ドキュメントが上位に表示されており、検索精度が高いことを示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mrr_byid(all_result_ids, rel_set, k=10):\n",
    "    mrrs = []\n",
    "    for n in all_result_ids.keys():\n",
    "        query_index = n\n",
    "        retrieved_ids = all_result_ids[n][:k]\n",
    "        relevant_ids = set(rel_set.get(query_index, []))\n",
    "\n",
    "        # Find the rank of the first relevant document\n",
    "        first_relevant_rank = None\n",
    "        for rank, doc_id in enumerate(retrieved_ids, start=1):\n",
    "            if doc_id in relevant_ids:\n",
    "                first_relevant_rank = rank\n",
    "                break\n",
    "\n",
    "        # Calculate MRR for this query\n",
    "        mrr = 1 / first_relevant_rank if first_relevant_rank else 0.0\n",
    "        mrrs.append(mrr)\n",
    "\n",
    "        # Debug print to see MRR for each query\n",
    "        # print(f\"MRR for query {query_index}: {mrr:.4f}\")\n",
    "\n",
    "    average_mrr = np.mean(mrrs)\n",
    "    print(f\"Average MRR over {len(all_result_ids.keys())} instances: {average_mrr:.4f}\")\n",
    "    return average_mrr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 速度の計測\n",
    "今回は簡易的な検証のため、専用のロードテストツールではなくJupyter Notebook上で以下のように検証を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def perform_search(test_df, search_function, get_data_function, k=10, num_iterations=1):\n",
    "    percentile_90_list = []\n",
    "    percentile_99_list = []\n",
    "    total_execution_times = []\n",
    "    all_result_ids = {}\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        print(f\"Iteration {i+1}\")\n",
    "\n",
    "        search_times = []\n",
    "        for index, query_text in tqdm(filtered_qry_set.items(), desc=\"Searching\"):\n",
    "            vector = np.array(test_df[test_df['id'] == index].iloc[0]['vector'])\n",
    "            start_time = time.time()\n",
    "            try:\n",
    "                response = search_function(vector, query_text)\n",
    "            except Exception as e:\n",
    "                print(f\"Error occurred for index {index}: {e}\")\n",
    "                continue\n",
    "\n",
    "            end_time = time.time()\n",
    "            search_times.append(end_time - start_time)\n",
    "\n",
    "            data = get_data_function(response)\n",
    "\n",
    "            result_ids = [int(res_id) for res_id in data[:k]]  # 上位k件のドキュメントIDを取得\n",
    "            all_result_ids[index] = result_ids\n",
    "\n",
    "        df = pd.DataFrame(search_times, columns=['search_time'])\n",
    "\n",
    "        percentile_90 = df['search_time'].quantile(0.9) * 1000  # ミリ秒に変換\n",
    "        percentile_99 = df['search_time'].quantile(0.99) * 1000  # ミリ秒に変換\n",
    "\n",
    "        percentile_90_list.append(percentile_90)\n",
    "        percentile_99_list.append(percentile_99)\n",
    "        total_execution_times.append(sum(search_times))\n",
    "\n",
    "        print(\"Total execution time for searches: {:.3f} s\".format(sum(search_times)))\n",
    "        print(\"90th percentile of search times: {:.3f} ms\".format(percentile_90))\n",
    "        print(\"99th percentile of search times: {:.3f} ms\".format(percentile_99))\n",
    "\n",
    "    average_90 = np.mean(percentile_90_list)\n",
    "    std_90 = np.std(percentile_90_list)\n",
    "\n",
    "    average_99 = np.mean(percentile_99_list)\n",
    "    std_99 = np.std(percentile_99_list)\n",
    "\n",
    "    average_total_time = np.mean(total_execution_times)\n",
    "    std_total_time = np.std(total_execution_times)\n",
    "\n",
    "    print(\"Average total execution time: {:.3f} s (std: {:.3f})\".format(average_total_time, std_total_time))\n",
    "    print(\"Average 90th percentile of search times: {:.3f} ms (std: {:.3f})\".format(average_90, std_90))\n",
    "    print(\"Average 99th percentile of search times: {:.3f} ms (std: {:.3f})\".format(average_99, std_99))\n",
    "\n",
    "    return all_result_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vald"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import grpc\n",
    "from vald.v1.vald import insert_pb2_grpc\n",
    "from vald.v1.vald import upsert_pb2_grpc\n",
    "from vald.v1.vald import search_pb2_grpc\n",
    "from vald.v1.vald import update_pb2_grpc\n",
    "from vald.v1.vald import remove_pb2_grpc\n",
    "from vald.v1.vald import object_pb2_grpc\n",
    "from vald.v1.vald import index_pb2_grpc\n",
    "from vald.v1.payload import payload_pb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "PORT_DEFAULT = ':8081'\n",
    "host = \"vald-lb-gateway.test-ns.svc.cluster.local\"\n",
    "\n",
    "options = [\n",
    "    ('grpc.max_metadata_size', 32 * 1024),\n",
    "]\n",
    "\n",
    "## create a channel by passing \"{host}:{port}\"\n",
    "channel = grpc.insecure_channel(host + PORT_DEFAULT, options=options)\n",
    "\n",
    "## create stubs for calling RPCs\n",
    "insertStub = insert_pb2_grpc.InsertStub(channel)\n",
    "upsertStub = upsert_pb2_grpc.UpsertStub(channel)\n",
    "updateStub = update_pb2_grpc.UpdateStub(channel)\n",
    "removeStub = remove_pb2_grpc.RemoveStub(channel)\n",
    "objectStub = object_pb2_grpc.ObjectStub(channel)\n",
    "searchStub = search_pb2_grpc.SearchStub(channel)\n",
    "indexStub = index_pb2_grpc.IndexStub(channel)\n",
    "\n",
    "insertConfig = payload_pb2.Insert.Config(skip_strict_exist_check=True)\n",
    "updateConfig = payload_pb2.Update.Config(skip_strict_exist_check=True)\n",
    "removeConfig = payload_pb2.Remove.Config(skip_strict_exist_check=True)\n",
    "upsertConfig = payload_pb2.Upsert.Config(skip_strict_exist_check=True)\n",
    "searchConfig = payload_pb2.Search.Config(num=10, radius=-1.0, epsilon=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generatorUpsertStream():\n",
    "    upsert_requests = []\n",
    "    for _, row in tqdm(train_df.iterrows()):\n",
    "        v = payload_pb2.Object.Vector(id=str(row['id']), vector=row['vector'])\n",
    "        request = payload_pb2.Upsert.Request(vector=v, config=upsertConfig)\n",
    "        upsert_requests.append(request)\n",
    "    return upsert_requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Stream Upsert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1460it [00:00, 4114.34it/s]\n",
      "1460it [00:01, 1046.15it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "print('Start Stream Upsert')\n",
    "for r in tqdm(upsertStub.StreamUpsert(iter(generatorUpsertStream()))):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing完了確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current index count: 4380\n",
      "Indexing completed in: 0.00 seconds\n"
     ]
    }
   ],
   "source": [
    "index_count = 1460\n",
    "check_interval = 5 # チェック間隔（秒）\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "while True:\n",
    "    res = indexStub.IndexInfo(payload_pb2.Empty())\n",
    "    current_count = res.stored\n",
    "\n",
    "    print(f\"Current index count: {current_count}\")\n",
    "\n",
    "    if current_count >= index_count * 3: # index_replica=3\n",
    "        end_time = time.time()\n",
    "        print(\"Indexing completed in: {:.2f} seconds\".format(end_time - start_time))\n",
    "        break\n",
    "\n",
    "    time.sleep(check_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Searching: 100%|██████████| 76/76 [00:00<00:00, 479.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total execution time for searches: 0.137 s\n",
      "90th percentile of search times: 2.215 ms\n",
      "99th percentile of search times: 2.519 ms\n",
      "Average total execution time: 0.137 s (std: 0.000)\n",
      "Average 90th percentile of search times: 2.215 ms (std: 0.000)\n",
      "Average 99th percentile of search times: 2.519 ms (std: 0.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def vald_search_function(vector, _,):\n",
    "    response = searchStub.Search(payload_pb2.Search.Request(vector=vector, config=searchConfig))\n",
    "    return response\n",
    "def vald_get_data_from_response(response):\n",
    "    return [int(result.id) for result in response.results]\n",
    "    \n",
    "# Vald\n",
    "vald_all_result_ids = perform_search(test_df, vald_search_function, vald_get_data_from_response, k=20, num_iterations=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MRR over 76 instances: 0.6157\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6157111528822055"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_mrr_byid(vald_all_result_ids, rel_set, k=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opensearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opensearchpy import OpenSearch\n",
    "from opensearchpy.exceptions import ConnectionError\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib3\n",
    "# InsecureRequestWarningを無効化\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_admin_password = '' # set your password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenSearch(\n",
    "    hosts=[{'host': 'my-third-cluster.opensearch-3.svc.cluster.local', 'port': 9200}],\n",
    "    http_auth=('admin', initial_admin_password),\n",
    "    use_ssl=True,\n",
    "    verify_certs=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_documents(doc_set, train_df, index_name, hybrid=False):\n",
    "    for doc_id, doc_text in tqdm(doc_set.items()):\n",
    "        document = {\n",
    "            'doc_id': doc_id,\n",
    "            'text': doc_text,\n",
    "        }\n",
    "\n",
    "        if hybrid:\n",
    "            document['passage_embedding'] = np.array(train_df.iloc[doc_id - 1].vector)\n",
    "\n",
    "        response = client.index(\n",
    "            index=index_name,\n",
    "            id=doc_id,\n",
    "            body=document\n",
    "        )\n",
    "        # print(f'Document {doc_id} indexed with response: {response[\"result\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1460/1460 [00:04<00:00, 349.23it/s]\n",
      "100%|██████████| 1460/1460 [00:07<00:00, 194.19it/s]\n"
     ]
    }
   ],
   "source": [
    "text_index_name = 'cisi-text'\n",
    "index_documents(doc_set, train_df, text_index_name, hybrid=False)\n",
    "\n",
    "vector_index_name = 'cisi-text-hybrid'\n",
    "index_documents(doc_set, train_df, vector_index_name, hybrid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing完了確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current document count: 1460\n",
      "Indexing completed in 0.00 seconds.\n"
     ]
    }
   ],
   "source": [
    "index_name = 'cisi-text-hybrid'\n",
    "index_count = 1460\n",
    "check_interval = 5 # チェック間隔（秒）\n",
    "\n",
    "def get_document_count(index_name):\n",
    "    try:\n",
    "        response = client.indices.stats(index=index_name)\n",
    "        doc_count = response['_all']['primaries']['docs']['count']\n",
    "        return doc_count\n",
    "    except ConnectionError as e:\n",
    "        print(f\"Connection error: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "while True:\n",
    "    doc_count = get_document_count(index_name)\n",
    "    \n",
    "    if doc_count is not None:\n",
    "        print(f\"Current document count: {doc_count}\")\n",
    "\n",
    "        if doc_count >= index_count:\n",
    "            end_time = time.time()\n",
    "            elapsed_time = end_time - start_time\n",
    "            print(f\"Indexing completed in {elapsed_time:.2f} seconds.\")\n",
    "            break\n",
    "\n",
    "    time.sleep(check_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_search(vector, query_text):\n",
    "    search_query = {\n",
    "        \"size\": 20,  # 最大20件取得\n",
    "        \"query\": {\n",
    "            \"match\": {\n",
    "                \"text\": {\n",
    "                    \"query\": query_text,\n",
    "                    \"minimum_should_match\": \"30%\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = client.search(\n",
    "        index=text_index_name,\n",
    "        body=search_query,\n",
    "        params={}\n",
    "    )\n",
    "    return response\n",
    "\n",
    "def hybrid_search(vector, query_text):\n",
    "    search_query = {\n",
    "        \"_source\": {\n",
    "            \"exclude\": [\n",
    "                \"passage_embedding\"\n",
    "            ]\n",
    "        },\n",
    "        \"size\": 20,  # 最大20件取得\n",
    "        \"query\": {\n",
    "            \"hybrid\": {\n",
    "                \"queries\": [\n",
    "                    {\n",
    "                        \"match\": {\n",
    "                            \"text\": {\n",
    "                                \"query\": query_text,\n",
    "                                \"minimum_should_match\": \"30%\",\n",
    "                            }\n",
    "                        }\n",
    "                    },\n",
    "                    {\n",
    "                        \"knn\": {\n",
    "                            \"passage_embedding\": {\n",
    "                                \"vector\": vector,\n",
    "                                \"k\": 20    \n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    search_pipeline = 'hybrid-search-pipeline'\n",
    "    params={\"search_pipeline\": search_pipeline}\n",
    "\n",
    "    response = client.search(\n",
    "        index=vector_index_name,\n",
    "        body=search_query,\n",
    "        params=params\n",
    "    )\n",
    "    return response\n",
    "\n",
    "def vector_search(vector, query_text):\n",
    "    search_query = {\n",
    "        \"_source\": {\n",
    "            \"exclude\": [\n",
    "                \"passage_embedding\"\n",
    "            ]\n",
    "        },\n",
    "        \"size\": 20,  # 最大20件取得\n",
    "        \"query\": {\n",
    "            \"knn\": {\n",
    "                \"passage_embedding\": {\n",
    "                    \"vector\": vector,\n",
    "                    \"k\": 20    \n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    params = {}\n",
    "\n",
    "    response = client.search(\n",
    "        index=vector_index_name,\n",
    "        body=search_query,\n",
    "        params=params\n",
    "    )\n",
    "    return response\n",
    "\n",
    "def opensearch_get_data_from_response(response):\n",
    "    return [int(res['_id']) for res in response['hits']['hits']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Searching: 100%|██████████| 76/76 [00:00<00:00, 136.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total execution time for searches: 0.529 s\n",
      "90th percentile of search times: 10.471 ms\n",
      "99th percentile of search times: 17.033 ms\n",
      "Average total execution time: 0.529 s (std: 0.000)\n",
      "Average 90th percentile of search times: 10.471 ms (std: 0.000)\n",
      "Average 99th percentile of search times: 17.033 ms (std: 0.000)\n",
      "Average MRR over 76 instances: 0.6059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6058757633835034"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 全文検索\n",
    "opensearch_full_all_result_ids = perform_search(test_df, full_search, opensearch_get_data_from_response, k=20, num_iterations=1)\n",
    "calculate_mrr_byid(opensearch_full_all_result_ids, rel_set, k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Searching: 100%|██████████| 76/76 [00:01<00:00, 51.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total execution time for searches: 1.433 s\n",
      "90th percentile of search times: 23.414 ms\n",
      "99th percentile of search times: 31.956 ms\n",
      "Average total execution time: 1.433 s (std: 0.000)\n",
      "Average 90th percentile of search times: 23.414 ms (std: 0.000)\n",
      "Average 99th percentile of search times: 31.956 ms (std: 0.000)\n",
      "Average MRR over 76 instances: 0.6618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6617831716108561"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ハイブリッドサーチ\n",
    "opensearch_hybrid_all_result_ids = perform_search(test_df, hybrid_search, opensearch_get_data_from_response, k=20, num_iterations=1)\n",
    "calculate_mrr_byid(opensearch_hybrid_all_result_ids, rel_set, k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Searching: 100%|██████████| 76/76 [00:00<00:00, 99.70it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total execution time for searches: 0.731 s\n",
      "90th percentile of search times: 10.339 ms\n",
      "99th percentile of search times: 15.210 ms\n",
      "Average total execution time: 0.731 s (std: 0.000)\n",
      "Average 90th percentile of search times: 10.339 ms (std: 0.000)\n",
      "Average 99th percentile of search times: 15.210 ms (std: 0.000)\n",
      "Average MRR over 76 instances: 0.6198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6198466372808479"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ベクトル検索\n",
    "opensearch_vector_all_result_ids = perform_search(test_df, vector_search, opensearch_get_data_from_response, k=20, num_iterations=1)\n",
    "calculate_mrr_byid(opensearch_vector_all_result_ids, rel_set, k=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 謝辞\n",
    "データセットを作成いただいたグラスゴー大学の方々、Kaggleのデータセットを作成いただいたHJMason様に感謝申し上げます。\n",
    "\n",
    "Riddhi Pawar様の[Notebook](https://www.kaggle.com/code/rid17pawar/semantic-search-using-mean-of-vectors)を参考にさせていただきました。感謝申し上げます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
